<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Jurvise AI Assistant</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');
        body {
            font-family: 'Inter', sans-serif;
            background-color: #1f2937;
            color: #e5e7eb;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
        }
        .container {
            max-width: 6xl;
            width: 100%;
            margin: 24px;
        }
        .pulse-effect {
            animation: pulse-ring 1.5s cubic-bezier(0.25, 0.46, 0.45, 0.94) infinite;
        }
        @keyframes pulse-ring {
            0% {
                box-shadow: 0 0 0 0 #6ee7b7;
            }
            80% {
                box-shadow: 0 0 0 20px rgba(110, 231, 183, 0);
            }
            100% {
                box-shadow: 0 0 0 20px rgba(110, 231, 183, 0);
            }
        }
        .modal {
            display: none;
            position: fixed;
            z-index: 100;
            left: 0;
            top: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0,0,0,0.5);
            backdrop-filter: blur(5px);
            -webkit-backdrop-filter: blur(5px);
            justify-content: center;
            align-items: center;
        }
        .modal-content {
            background-color: #374151;
            padding: 24px;
            border-radius: 12px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            width: 90%;
            max-width: 400px;
        }
        .loader {
            border: 4px solid #f3f3f3;
            border-top: 4px solid #3b82f6;
            border-radius: 50%;
            width: 24px;
            height: 24px;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
    </style>
</head>
<body class="p-6 md:p-12">
    <!-- Main UI Container -->
    <div class="container bg-gray-800 rounded-2xl shadow-xl p-8 sm:p-12 text-center border border-gray-700">
        <!-- Header -->
        <header class="flex flex-col items-center justify-center mb-10">
            <h1 class="text-5xl md:text-6xl font-extrabold text-blue-400 mb-2">Jurvise</h1>
            <p class="text-xl text-gray-400 font-medium">Your Personal AI Assistant</p>
        </header>

        <!-- Status and Command Button -->
        <div class="space-y-6">
            <div id="status" class="text-lg font-semibold text-gray-300 h-6">Ready to assist.</div>
            <button id="startBtn" class="bg-blue-600 hover:bg-blue-700 text-white font-bold py-4 px-8 rounded-full shadow-lg transition-all duration-300 transform hover:scale-105 focus:outline-none focus:ring-4 focus:ring-blue-500 focus:ring-opacity-50">
                Start Jurvise
            </button>
        </div>

        <!-- Conversation Log -->
        <div class="mt-12 text-left bg-gray-900 p-6 rounded-xl border border-gray-700 shadow-inner">
            <h2 class="text-2xl font-semibold mb-4 text-white">Conversation</h2>
            <div id="conversationLog" class="space-y-6 text-sm md:text-base">
                <div class="text-gray-400 italic">... Conversation history will appear here ...</div>
            </div>
        </div>
    </div>

    <!-- Custom Alert Modal -->
    <div id="customAlertModal" class="modal">
        <div class="modal-content text-center">
            <h2 id="customAlertTitle" class="text-xl font-semibold mb-2 text-white"></h2>
            <p id="customAlertMessage" class="text-gray-400 mb-4"></p>
            <div class="flex justify-end">
                <button id="customAlertOkBtn" class="bg-blue-500 hover:bg-blue-600 text-white font-medium py-2 px-4 rounded-full">OK</button>
            </div>
        </div>
    </div>

    <script type="module">
        // Global variables for API keys and endpoint
        const apiKey = "";
        const geminiApiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent?key=${apiKey}`;
        const ttsApiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${apiKey}`;

        // UI elements
        const startBtn = document.getElementById('startBtn');
        const statusEl = document.getElementById('status');
        const conversationLog = document.getElementById('conversationLog');
        const customAlertModal = document.getElementById('customAlertModal');
        const customAlertTitle = document.getElementById('customAlertTitle');
        const customAlertMessage = document.getElementById('customAlertMessage');
        const customAlertOkBtn = document.getElementById('customAlertOkBtn');
        
        let recognition = null;
        let isListening = false;
        let isSpeaking = false;
        let audioContext = null;

        // --- Custom Alert Logic ---
        function showAlert(title, message) {
            customAlertTitle.textContent = title;
            customAlertMessage.textContent = message;
            customAlertModal.style.display = 'flex';
        }

        customAlertOkBtn.addEventListener('click', () => {
            customAlertModal.style.display = 'none';
        });

        window.onclick = function(event) {
            if (event.target == customAlertModal) {
                customAlertModal.style.display = 'none';
            }
        };
        
        // --- Helper for API Calls with Exponential Backoff ---
        // This function will retry failed API calls to handle transient network issues.
        async function retryFetch(url, options, retries = 3, delay = 1000) {
            try {
                const response = await fetch(url, options);
                if (!response.ok) {
                    if (response.status === 429 && retries > 0) { // Too Many Requests
                        console.warn(`API call failed with status ${response.status}. Retrying in ${delay}ms...`);
                        await new Promise(res => setTimeout(res, delay));
                        return retryFetch(url, options, retries - 1, delay * 2);
                    }
                    throw new Error(`API response error: ${response.status} ${response.statusText}`);
                }
                return response;
            } catch (error) {
                if (retries > 0) {
                    console.warn(`Network error. Retrying in ${delay}ms...`, error);
                    await new Promise(res => setTimeout(res, delay));
                    return retryFetch(url, options, retries - 1, delay * 2);
                }
                throw error;
            }
        }

        // --- Speech Recognition Setup ---
        // Check for browser support
        if ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window) {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            recognition = new SpeechRecognition();
            recognition.continuous = false;
            recognition.interimResults = false;
            recognition.lang = 'en-US';

            recognition.onresult = async (event) => {
                const transcript = event.results[0][0].transcript;
                const cleanTranscript = transcript.toLowerCase().trim();

                addMessageToLog('You', transcript);

                // Check for "Hello Jurvise" or "Hello Jarvis" using includes() for more flexibility
                if (cleanTranscript.includes('hello jurvise') || cleanTranscript.includes('hello jarvis')) {
                    const responseText = "Yes, boss.";
                    addMessageToLog('Jurvise', responseText);
                    await speakJurviseResponse(responseText);
                } else {
                    await getJurviseResponse(transcript);
                }
            };

            recognition.onend = () => {
                isListening = false;
                updateUI('idle');
            };

            recognition.onerror = (event) => {
                console.error('Speech recognition error:', event.error);
                if (event.error === 'no-speech' || event.error === 'audio-capture') {
                     // Do nothing, these are common and not a major error for a simple use case
                } else {
                    showAlert('Speech Error', `Recognition error: ${event.error}`);
                }
                isListening = false;
                updateUI('idle');
            };

        } else {
            showAlert('Browser Not Supported', 'Your browser does not support the Web Speech API. Please use Chrome or Edge.');
            startBtn.disabled = true;
        }

        // --- UI State Management ---
        function updateUI(state) {
            const btn = startBtn;
            btn.classList.remove('bg-green-600', 'bg-blue-600', 'bg-gray-500', 'bg-red-600', 'hover:bg-green-700', 'hover:bg-blue-700', 'hover:bg-red-700', 'cursor-not-allowed', 'pulse-effect');
            
            if (state === 'listening') {
                statusEl.textContent = 'Listening...';
                btn.textContent = 'Speak Now';
                btn.classList.add('bg-green-600', 'hover:bg-green-700', 'pulse-effect');
                btn.disabled = false;
            } else if (state === 'thinking') {
                statusEl.textContent = 'Thinking...';
                btn.textContent = 'Jurvise is thinking...';
                btn.classList.add('bg-gray-500', 'cursor-not-allowed');
                btn.disabled = true;
            } else if (state === 'speaking') {
                statusEl.textContent = 'Speaking...';
                btn.textContent = 'Jurvise is speaking...';
                btn.classList.add('bg-gray-500', 'cursor-not-allowed');
                btn.disabled = true;
            } else { // idle
                statusEl.textContent = 'Ready to assist.';
                btn.textContent = 'Start Jurvise';
                btn.classList.add('bg-blue-600', 'hover:bg-blue-700');
                btn.disabled = false;
            }
        }
        
        // --- Gemini API Logic ---
        async function getJurviseResponse(prompt) {
            updateUI('thinking');
            const systemPrompt = "You are a helpful AI assistant named Jurvise. Your purpose is to provide concise, helpful, and conversational responses. You do not have a physical form, so do not refer to yourself as a physical being. Respond in a friendly and professional tone, similar to an AI assistant from a movie. Keep your answers brief and to the point.";

            const payload = {
                contents: [{ parts: [{ text: prompt }] }],
                systemInstruction: {
                    parts: [{ text: systemPrompt }]
                },
            };
            
            try {
                const response = await retryFetch(geminiApiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                const result = await response.json();
                const jurviseText = result?.candidates?.[0]?.content?.parts?.[0]?.text;

                if (jurviseText) {
                    addMessageToLog('Jurvise', jurviseText);
                    await speakJurviseResponse(jurviseText);
                } else {
                    addMessageToLog('Jurvise', 'I am sorry, I could not generate a response.');
                    updateUI('idle');
                }
            } catch (error) {
                console.error("Error with Gemini API:", error);
                addMessageToLog('Jurvise', `There was an error processing your request: ${error.message}`);
                showAlert('API Error', 'Failed to get a response from the AI. The service may be temporarily unavailable.');
                updateUI('idle');
            }
        }
        
        // --- TTS API Logic ---
        async function speakJurviseResponse(text) {
            updateUI('speaking');
            isSpeaking = true;
            const payload = {
                contents: [{ parts: [{ text: text }] }],
                generationConfig: {
                    responseModalities: ["AUDIO"],
                    speechConfig: {
                        voiceConfig: {
                            prebuiltVoiceConfig: { voiceName: "Rasalgethi" }
                        }
                    }
                },
                model: "gemini-2.5-flash-preview-tts"
            };

            try {
                const response = await retryFetch(ttsApiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });
                
                const result = await response.json();
                console.log("TTS API raw result:", result); // Added for debugging
                
                const part = result?.candidates?.[0]?.content?.parts?.[0];
                console.log("TTS API part:", part); // Added for debugging
                
                const audioData = part?.inlineData?.data;
                const mimeType = part?.inlineData?.mimeType;

                if (audioData && mimeType && mimeType.startsWith("audio/")) {
                    const pcmData = base64ToArrayBuffer(audioData);
                    const sampleRateMatch = mimeType.match(/rate=(\d+)/);
                    const sampleRate = sampleRateMatch ? parseInt(sampleRateMatch[1], 10) : 16000;
                    await playPcmAudio(pcmData, sampleRate);
                } else {
                    console.error("No valid audio data received from TTS API.");
                    showAlert('Audio Error', 'Could not generate speech. Please try again.');
                }
            } catch (error) {
                console.error("Error with TTS API:", error);
                showAlert('API Error', `Failed to generate speech: ${error.message}. The TTS service may be temporarily unavailable.`);
            } finally {
                isSpeaking = false;
                updateUI('idle');
            }
        }

        function base64ToArrayBuffer(base64) {
            const binaryString = atob(base64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer;
        }

        async function playPcmAudio(pcmData, sampleRate) {
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }
            
            const int16Array = new Int16Array(pcmData);
            const float32Array = new Float32Array(int16Array.length);

            for (let i = 0; i < int16Array.length; i++) {
                float32Array[i] = int16Array[i] / 32768.0;
            }

            const audioBuffer = audioContext.createBuffer(1, float32Array.length, sampleRate);
            audioBuffer.copyToChannel(float32Array, 0);

            const source = audioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(audioContext.destination);
            
            return new Promise((resolve, reject) => {
                source.onended = () => resolve();
                source.start();
            });
        }
        
        // --- Conversation Log UI ---
        function addMessageToLog(sender, message) {
            const logItem = document.createElement('div');
            logItem.className = sender === 'You' ? 'text-right' : 'text-left';
            logItem.innerHTML = `
                <div class="bg-gray-700 p-4 rounded-lg inline-block max-w-full">
                    <span class="font-bold text-blue-300">${sender}:</span>
                    <span class="text-gray-200">${message}</span>
                </div>
            `;
            conversationLog.appendChild(logItem);
            conversationLog.scrollTop = conversationLog.scrollHeight;
        }

        // --- Main Button Event Listener ---
        startBtn.addEventListener('click', () => {
            if (!recognition) {
                return;
            }

            if (isListening) {
                recognition.stop();
                updateUI('idle');
            } else {
                if (isSpeaking) {
                    return;
                }
                try {
                    recognition.start();
                    isListening = true;
                    updateUI('listening');
                } catch (e) {
                    console.error("Recognition start error:", e);
                    showAlert('Error', `Could not start microphone. Please check your browser permissions.`);
                    updateUI('idle');
                }
            }
        });

        // Initial UI setup
        updateUI('idle');
    </script>
</body>
</html>
